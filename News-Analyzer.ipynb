{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Trends in News Headlines\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data\n",
    "---\n",
    "\n",
    "* Where I am getting the data\n",
    "* Talk about running a server on DigitalOcean\n",
    "* Show part of the python `scraper.py` script\n",
    "* Talk about the identifies, N, J, what they mean\n",
    "* Talk about the Watson API\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "For my sources I decided to use the homepage of [RT](https://www.rt.com/), the politics page of [The Washington Times](http://www.washingtontimes.com/news/politics/), and the politics page of [CBC News](http://www.cbc.ca/news/politics). I choose these three news networks, because they were best known to me.\n",
    "\n",
    "I made a Python script `scraper.py` to scrape these individual webpages and collect news headlines at different times during the day. The script would scrape all three websites in the morning at around 11:00AM, then during the day at around 14:00PM. and finally in the evening at 18:00PM. \n",
    "\n",
    "The reason for having three different news networks and setting the script to scrape at differnt times throughout the day, is because I was trying to get as much variation as possible, to help me find more patterns from the data.\n",
    "\n",
    "### Automating Work\n",
    "\n",
    "To save my self the time and headache of remembering to scrape the websites at certain times, I spun a simple Ubuntu droplet on DigitalOcean. I used the [Python Schedule package](https://pypi.python.org/pypi/schedule) to automate the script to run at specific times throughout the day.\n",
    "\n",
    "To run the script as a background process I used the following command `nohup python3 scraper.py > scraper.out 2>scraper.err &`.\n",
    "\n",
    "\n",
    "### Watson API\n",
    "\n",
    "To analyze the news headlines I used IBM's Watson [Natural Language Understanding](https://natural-language-understanding-demo.mybluemix.net/) API. The Natural Language Understanding (NLU) is a collection of differnt APIs that analyze text to help you understand its concepts, entities, keywords, sentiment, and more.\n",
    "\n",
    "For every news headline I requested the sentiment (provides a score for text either negative, positive, or neutral), emotions (joy, anger, disgust, sadness, and fear), and entities (identifies people, companies, countries, etc.) to be returned by the NLU API.\n",
    "\n",
    "### Scraper Script\n",
    "\n",
    "The following is a chunk from the `scraper.py` script, the chunk is used to scraper, analyse, and then write the information (news headlines and their analysis) to a `.txt` file from the RT homepage.\n",
    "\n",
    "```python\n",
    "\n",
    "def RT():\n",
    "\n",
    "    ...\n",
    "\n",
    "    with open(filename, mode) as fp:\n",
    "\n",
    "        # Start of Russia Today news\n",
    "        fp.write('N RT\\n')\n",
    "\n",
    "        # Scrapes the website of Russia Today news network and writes news headlines to a file\n",
    "        for ul_tag in soup.find_all('ul', {'class': 'main-promobox__list'}):\n",
    "            for li_tag in ul_tag.find_all('li', {'class': 'main-promobox__item'}):\n",
    "                for headline in li_tag.find_all('a', {'class': 'main-promobox__link'}):\n",
    "\n",
    "                    news_headline = headline.text.lstrip().replace('\\n', '')\n",
    "\n",
    "                    fp.write('H ')\n",
    "                    fp.write(news_headline)\n",
    "                    fp.write('\\n')\n",
    "                    fp.write('J ')\n",
    "                    json.dump(NLU.analyze(text=news_headline, features=[features.Sentiment(), \n",
    "                            features.Emotion(), features.Entities()]), fp)\n",
    "                    fp.write('\\n')\n",
    "\n",
    "    ...\n",
    "    \n",
    "```\n",
    "\n",
    "### Storing Data\n",
    "\n",
    "The following is a chunk from one of the `.txt` files containing information (news headlines and their analysis) from all three news networks. The following shows information about the first two headlines from RT homepage.\n",
    "\n",
    "* **N** indicates the start of a new news network.\n",
    "* **H** indicates a new headline.\n",
    "* **J** indicates the NLU analysis of the above headline.\n",
    "\n",
    "```sh\n",
    "\n",
    "N RT\n",
    "H ‘It takes 2 to tango’: Germany threatens Turkey with major policy overhaul                                                                     \n",
    "J {\"sentiment\": {\"document\": {\"score\": -0.358041, \"label\": \"negative\"}}, \"entities\": [{\"text\": \"Germany\", \"count\": 1, \"disambiguation\": {\"subtype\": [\"Country\"]}, \"type\": \"Location\", \"relevance\": 0.33}, {\"text\": \"Turkey\", \"count\": 1, \"disambiguation\": {\"dbpedia_resource\": \"http://dbpedia.org/resource/Turkey\", \"subtype\": [\"Brand\", \"GovernmentalJurisdiction\", \"ProjectParticipant\", \"Country\"], \"name\": \"Turkey\"}, \"type\": \"Location\", \"relevance\": 0.33}], \"language\": \"en\", \"emotion\": {\"document\": {\"emotion\": {\"disgust\": 0.054634, \"joy\": 0.018692, \"fear\": 0.267773, \"anger\": 0.132166, \"sadness\": 0.068436}}}}\n",
    "H Trump to end lavish CIA support for ‘moderate’ anti-Assad forces in Syria – reports                                                                    \n",
    "J {\"sentiment\": {\"document\": {\"score\": 0.0, \"label\": \"neutral\"}}, \"entities\": [{\"text\": \"Syria\", \"count\": 1, \"disambiguation\": {\"subtype\": [\"Country\"]}, \"type\": \"Location\", \"relevance\": 0.33}, {\"text\": \"CIA\", \"count\": 1, \"type\": \"Organization\", \"relevance\": 0.33}], \"language\": \"en\", \"emotion\": {\"document\": {\"emotion\": {\"disgust\": 0.393306, \"joy\": 0.010359, \"fear\": 0.123981, \"anger\": 0.200277, \"sadness\": 0.42641}}}}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "---\n",
    "\n",
    "* Show the txt file, show how the data was initially being stored\n",
    "* Convert JSON objects into CSV\n",
    "* Remove irrelavent things from the Entities item, parse for `Trump` amd `Putin`\n",
    "* Figure something out with morning, day, and evening news\n",
    "    * Different starting dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data\n",
    "---\n",
    "\n",
    "* Compare Negative and Positive news\n",
    "    * How many Negative and Positive news in total - Pie Chart\n",
    "    * How does time of day effect the number of Negative and Positive news - Line Chart with specific time internval\n",
    "    * How does big celebrations (Stampede) effected the number of Negative News, did they increase or decrease over the course of that week - Line Chart only showing CBC news\n",
    "* Compare the Emoitions (Joy, Anger, Saddness, etc...)\n",
    "    * See which emotion doninates - Bubble Chart with bubbles being the emojis corresponding to the feeling\n",
    "    * Talk about why the dominant emotion doninates\n",
    "        * Talk about the Article (link in GDrive)\n",
    "* Draw a Line Chart with all the news, one chart for all networks in the morning, day, and evening\n",
    "    * Trying to see patterns, if they repeat the number of negatives news every week\n",
    "    * See if there are more negative news in the morning, day, or evening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent Data\n",
    "---\n",
    "\n",
    "* Who is the most mentioned president\n",
    "    * Trump, Putin, Trudeau - Pie Chart\n",
    "* Which country is the most mentioned\n",
    "    * Russia, America, Canada, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe srcdoc=\"\n",
       "        <!-- Load Google Charts -->\n",
       "        <script type='text/javascript' src='https://www.gstatic.com/charts/loader.js'></script>\n",
       "    \n",
       "        <div id=chart style='width: 100%; height: 100%' ></div>\n",
       "        <script type='text/javascript'>\n",
       "            google.charts.load('current', {'packages':['corechart']});\n",
       "            google.charts.setOnLoadCallback(drawChart);\n",
       "\n",
       "            function drawChart() {\n",
       "                var data = google.visualization.arrayToDataTable([\n",
       "    [\n",
       "        'Year',\n",
       "        'Sales',\n",
       "        'Expenses'\n",
       "    ],\n",
       "    [\n",
       "        '2004',\n",
       "        0,\n",
       "        400\n",
       "    ],\n",
       "    [\n",
       "        '2005',\n",
       "        1170,\n",
       "        460\n",
       "    ],\n",
       "    [\n",
       "        '2006',\n",
       "        660,\n",
       "        1120\n",
       "    ],\n",
       "    [\n",
       "        '2007',\n",
       "        1030,\n",
       "        540\n",
       "    ]\n",
       "]\n",
       "                );\n",
       "\n",
       "                var chart = new google.visualization.LineChart(document.getElementById('chart'));\n",
       "\n",
       "                chart.draw(data, {\n",
       "    'height': 400,\n",
       "    'width': 600,\n",
       "    'curveType': 'function'\n",
       "});\n",
       "            }\n",
       "        </script>\n",
       "    \" src=\"\" width=\"800\" height=\"420\" frameborder=0 sandbox=\"allow-scripts\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from iplotter import GCPlotter\n",
    "\n",
    "plotter = GCPlotter()\n",
    "\n",
    "data = [\n",
    "    ['Year', 'Sales', 'Expenses'],\n",
    "    ['2004',  0,      400],\n",
    "    ['2005',  1170,      460],\n",
    "    ['2006',  660,       1120],\n",
    "    ['2007',  1030,      540]\n",
    "]\n",
    "\n",
    "options = {\n",
    "    \"width\": 600,\n",
    "    \"height\": 400,\n",
    "    \"curveType\": 'function',\n",
    "}\n",
    "\n",
    "plotter.plot(data, chart_type=\"LineChart\",chart_package='corechart', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
